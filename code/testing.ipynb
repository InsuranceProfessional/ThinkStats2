{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nThis file contains code for use with \"Think Stats\",<br>\n", "by Allen B. Downey, available from greenteapress.com<br>\n", "Copyright 2014 Allen B. Downey<br>\n", "License: GNU GPLv3 http://www.gnu.org/licenses/gpl.html<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function, division"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import sys"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nsfg\n", "import thinkstats2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set the directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.chdir(r\"C:\\Users\\champ\\OneDrive\\Documents\\DSC530 Data Exploration\\ThinkStats2\\code\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Verify the current working directory"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(os.getcwd())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ReadFemResp(dct_file='2002FemResp.dct',\n", "                dat_file='2002FemResp.dat.gz',\n", "                nrows=None):\n", "    \"\"\"Reads the NSFG respondent data.\n", "    dct_file: string file name\n", "    dat_file: string file name\n", "    returns: DataFrame\n", "    \"\"\"\n", "    dct = thinkstats2.ReadStataDct(dct_file)\n", "    df = dct.ReadFixedWidth(dat_file, compression='gzip', nrows=nrows)\n", "    CleanFemResp(df)\n", "    return df"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def CleanFemResp(df):\n", "    \"\"\"Recodes variables from the respondent frame.\n", "    df: DataFrame\n", "    \"\"\"\n", "    pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def ValidatePregnum(resp):\n", "    \"\"\"Validate pregnum in the respondent file.\n", "    resp: respondent DataFrame\n", "    \"\"\"\n", "    # read the pregnancy frame\n", "    preg = nsfg.ReadFemPreg()\n\n", "    # make the map from caseid to list of pregnancy indices\n", "    preg_map = nsfg.MakePregMap(preg)\n", "    \n", "    # iterate through the respondent pregnum series\n", "    for index, pregnum in resp.pregnum.items():\n", "        caseid = resp.caseid[index]\n", "        indices = preg_map[caseid]\n\n", "        # check that pregnum from the respondent file equals\n", "        # the number of records in the pregnancy file\n", "        if len(indices) != pregnum:\n", "            print(caseid, len(indices), pregnum)\n", "            return False\n", "    return True"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main(script):\n", "    \"\"\"Tests the functions in this module.\n", "    script: string script name\n", "    \"\"\"\n", "    resp = ReadFemResp()\n", "    assert(len(resp) == 7643)\n", "    assert(resp.pregnum.value_counts()[1] == 1267)\n", "    assert(ValidatePregnum(resp))\n", "    print('%s: All tests passed.' % script)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    main(*sys.argv)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}